# java config property file
# config the project
maxFetchingThread=50
maxParseThread=50

#pagesToFetch=1200000
pagesToFetch=2000

# database config
dbHost=127.0.0.1
dbPort=13306
dbUsername=webCrawler
dbPassword=webCrawler
dbName=webCrawler

# trimTags=css-script
isTrimTags=true


# auto change ip address
isAutoChangeIp=false

# proxy config
useProxy=false
proxyHost=10.4.20.2
proxyPort=3128
proxyUsername=""
proxyPassword=""


# log config
useFileLog=true
# logFile=log/crawler.log

# save status
isSaveStatus=true
# statusFolder=status
isResume=false

# save urls resume to one file, for now false is not supported
isResumeFromOneFile=true

# url regular expression
urlPattern=.*

# these file type will be ignored, use lowerCase
excludeType=jpg,jpeg,pdf,apk,zip,rar,7z,tar,gz,2z,gif,ttf,swf,doc

# set cookie
# todo set different cookie for different domain
isSetCookie=false
cookieString=userFromPsNeedShowTab=1; BAIDUID=8380D4E7F7F9AEDEF7F66B62FAD4DD2F:FG=1; BIDUPSID=8380D4E7F7F9AEDEF7F66B62FAD4DD2F; TIEBA_USERTYPE=6976bdb9dd93f1bee91db134; bdshare_firstime=1427991813528; BDUSS=FQNTVBRzgtUDNoY3NWalc2OHdlLX5OVDQxWU9KdHNBckVmMmtQNGYzVXp-VVJWQVFBQUFBJCQAAAAAAAAAAAEAAACfNwUfa2l3aTk1XzAxAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADNwHVUzcB1VTV; TIEBAUID=303f787d7ee361a3e7153ba8; rpln_guide=1; _ga=GA1.2.2064864397.1429608980; BDRCVFR[pFk3RZTk8a0]=I67x6TjHwwYf0; MCITY=-%3A; PSTM=1432284127; cflag=65151%3A3; BDRCVFR[feWj1Vr5u3D]=mk3SLVN4HKm; BDRCVFR[FhauBQh29_R]=mbxnW11j9Dfmh7GuZR8mvqV; H_PS_PSSID=13454_1421_13350_13074_14391_10812_14429_12868_14166_14295_10562_12723_14482_14329_12029_13935_14176_14269_8498_10632_14194; wise_device=0

useNodeCheck=false
nodesToCheck=#frs_list_pager;#thread_list